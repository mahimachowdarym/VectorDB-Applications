{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 58.2M/58.2M [00:01<00:00, 40.8MB/s]\n",
      "Generating train split: 100%|██████████| 404290/404290 [00:33<00:00, 12017.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('quora', split='train[240000:290000]', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the truth of life?\n",
      "What's the evil truth of life?\n",
      "Which is the best smartphone under 20K in India?\n",
      "Which is the best smartphone with in 20k in India?\n",
      "Steps taken by Canadian government to improve literacy rate?\n",
      "Can I send homemade herbal hair oil from India to US via postal or private courier services?\n",
      "What is a good way to lose 30 pounds in 2 months?\n",
      "What can I do to lose 30 pounds in 2 months?\n",
      "Which of the following most accurately describes the translation of the graph y = (x+3)^2 -2 to the graph of y = (x -2)^2 +2?\n",
      "How do you graph x + 2y = -2?\n",
      "--------------------------------------------------\n",
      "Number of questions: 100000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "for record in dataset['questions']:\n",
    "    questions.extend(record['text'])\n",
    "question = list(set(questions))\n",
    "print('\\n'.join(questions[:10]))\n",
    "print('-' * 50)\n",
    "print(f'Number of questions: {len(questions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry no cuda.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device != 'cuda':\n",
    "    print('Sorry no cuda.')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'which city is the most populated in the world?'\n",
    "xq = model.encode(query)\n",
    "xq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "class Utils:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  \n",
    "  def create_dlai_index_name(self, index_name):\n",
    "    openai_key = ''\n",
    "    if self.is_colab(): # google colab\n",
    "      from google.colab import userdata\n",
    "      openai_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "    else: # jupyter notebook\n",
    "      openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    return f'{index_name}-{openai_key[-36:].lower().replace(\"_\", \"-\")}'\n",
    "    \n",
    "  def is_colab(self):\n",
    "    return 'google.colab' in sys.modules\n",
    "\n",
    "  def get_openai_api_key(self):\n",
    "    _ = load_dotenv(find_dotenv())\n",
    "    return os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "  def get_pinecone_api_key(self):\n",
    "    _ = load_dotenv(find_dotenv())\n",
    "    return os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = Utils()\n",
    "PINECONE_API_KEY = utils.get_pinecone_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl-ai-dqqqxduwtcecsctr1h1epizf2ykv7cwxgrka\n",
      "<pinecone.data.index.Index object at 0x0000023D7EFDAC90>\n"
     ]
    }
   ],
   "source": [
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "INDEX_NAME = utils.create_dlai_index_name('dl-ai')\n",
    "\n",
    "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
    "    pinecone.delete_index(INDEX_NAME)\n",
    "print(INDEX_NAME)\n",
    "pinecone.create_index(name=INDEX_NAME, \n",
    "    dimension=model.get_sentence_embedding_dimension(), \n",
    "    metric='cosine',\n",
    "    spec=ServerlessSpec(cloud='aws', region='us-east-1'))\n",
    "\n",
    "index = pinecone.Index(INDEX_NAME)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:53<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size=200\n",
    "vector_limit=10000\n",
    "\n",
    "questions = question[:vector_limit]\n",
    "\n",
    "import json\n",
    "\n",
    "for i in tqdm(range(0, len(questions), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(questions))\n",
    "    # create IDs batch\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    # create metadata batch\n",
    "    metadatas = [{'text': text} for text in questions[i:i_end]]\n",
    "    # create embeddings\n",
    "    xc = model.encode(questions[i:i_end])\n",
    "    # create records list for upsert\n",
    "    records = zip(ids, xc, metadatas)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "  embedding = model.encode(query).tolist()\n",
    "  results = index.query(top_k=10, vector=embedding, include_metadata=True, include_values=False)\n",
    "  for result in results['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64: Which city has the most museums per capita?\n",
      "0.59: Which is the highest peak of the world?\n",
      "0.59: Which are the top 10 largest cities of India by area?\n",
      "0.58: What is the most dangerous city in USA?\n",
      "0.55: How many cities in china?\n",
      "0.54: What are the 20 most richest countries in the world?\n",
      "0.53: Why is Uttar Pradesh the most populous state in India?\n",
      "0.51: How many hotels are situated in cities?\n",
      "0.49: How do I Construct a multiple bar chart to show population in 10000 of the given cities?\n",
      "0.49: What were the largest cities in the Roman Empire?\n"
     ]
    }
   ],
   "source": [
    "run_query('which city has the highest population in the world?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87: How do I make cake?\n",
      "0.61: What is a cake mix?\n",
      "0.6: How do I bake a cake without an oven?\n",
      "0.55: What is the difference between chocolate and truffles and how are they made?\n",
      "0.53: How do you make a perfume out of Skittles?\n",
      "0.52: How do I make my chocolate last longer (preservation)?\n",
      "0.51: Where can I found adorable baked cupcakes in Gold Coast?\n",
      "0.49: How can I make a banana pudding without bananas?\n",
      "0.48: Where can I get great range of flavours for cupcakes at Gold Coast?\n",
      "0.43: Why is there no chocolate-flavored chewing gum?\n"
     ]
    }
   ],
   "source": [
    "query = 'how do i make chocolate cake?'\n",
    "run_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
